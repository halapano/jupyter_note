{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 2019-3-19 12:33:47\n",
    "> integrate data_analysis_python.ipynb with CRISP-DM framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "\n",
    "- Scipy: https://docs.scipy.org/doc/scipy/reference/genindex.html\n",
    "- Numpy: https://docs.scipy.org/doc/numpy/genindex.html\n",
    "- Pandas: http://pandas.pydata.org/pandas-docs/stable/genindex.html\n",
    "- Matplotlib: https://matplotlib.org/genindex.html\n",
    "- tslern: https://tslearn.readthedocs.io/en/latest/auto_examples/index.html\n",
    "- StatsModel: http://www.statsmodels.org/stable/index.html\n",
    "- \n",
    "\n",
    "- CA683_DataAnalytics_DataMining\n",
    "- CA659_MathmeticalMethod\n",
    "- https://otexts.com/fpp2/\n",
    "- Textbook: Python for Data Analysis\n",
    "- https://anomaly.io/moving-median-robust-anomaly/\n",
    "- YouDaoNoet: \n",
    "- https://machinelearningmastery.com/time-series-forecasting-methods-in-python-cheat-sheet/\n",
    "- https://pbpython.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem recognition/Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine Business Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess Situation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine Data Mining Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect Raw Data\n",
    "\n",
    "- long format for multiple time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tslearn.datasets\n",
    "\n",
    "```\n",
    "from tslearn.datasets import UCR_UEA_datasets\n",
    "\n",
    "datasets = datasets = UCR_UEA_datasets()\n",
    "\n",
    "dataset_list = datasets.list_datasets()\n",
    "\n",
    "output = 'ucr_uea_datasets_list.txt'\n",
    "with open(join(PROJECT_PATH,output),'w+') as f:\n",
    "  f.write(str(dataset_list))\n",
    "\n",
    "> see content/drive/My Drive/DCU/practicum/ucr_uea_datasets_list.txt\n",
    "\n",
    "ecg200 = datasets.load_dataset('ECG200')\n",
    "\n",
    "# Directly unpack a tuple, return 4 numpy.ndarray\n",
    "X_train, y_train, X_test, y_test = ecg200\n",
    "\n",
    "X_train.shape\n",
    "> (100, 96, 1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe Data\n",
    "- index or columns are all the pandas datatype.\n",
    "    - df.index\n",
    "    - df.columns\n",
    "- append Concatenate with additional Index objects, producing a new Index\n",
    "- difference Compute set difference as an Index\n",
    "- intersection Compute set intersection\n",
    "- union Compute set union\n",
    "- isin Compute boolean array indicating whether each value is contained in the passed collection\n",
    "- delete Compute new Index with element at index i deleted\n",
    "- drop Compute new Index by deleting passed values\n",
    "- insert Compute new Index by inserting element at index i\n",
    "- is_monotonic Returns True if each element is greater than or equal to the previous element\n",
    "- is_unique Returns True if the Index has no duplicate values\n",
    "- unique Compute the array of unique values in the Index\n",
    "- value_counts()\n",
    "- isin Compute boolean array indicating whether each Series value is contained in the passed sequence ofvalues\n",
    "- match Compute integer indices for each value in an array into another array of distinct values; helpful for data alignment and join-type operations\n",
    "- unique Compute array of unique values in a Series, returned in the order observed\n",
    "- value_counts Return a Series containing unique values as its index and frequencies as its values, ordered count in descending order\n",
    "\n",
    "\n",
    "> py for da, page 160, table 5-8\n",
    "- count Number of non-NA values\n",
    "- describe Compute set of summary statistics for Series or each DataFrame column\n",
    "- min, max Compute minimum and maximum values\n",
    "- argmin, argmax Compute index locations (integers) at which minimum or maximum value obtained, respectively\n",
    "- idxmin, idxmax Compute index labels at which minimum or maximum value obtained, respectively\n",
    "- quantile Compute sample quantile ranging from 0 to 1\n",
    "- sum Sum of values\n",
    "- mean Mean of values\n",
    "- median Arithmetic median (50% quantile) of values\n",
    "- mad Mean absolute deviation from mean value\n",
    "- prod Product of all values\n",
    "\n",
    "- var Sample variance of values\n",
    "\\begin{equation*}\n",
    "\\sigma^2 (x) = E[(X-E(X))^2] =  E[(x-\\mu)^2]\n",
    "\\end{equation*}\n",
    "\n",
    "- std Sample standard deviation of values\n",
    "\\begin{equation*}\n",
    "\\sigma(x) = \\sqrt{E[(X-E(X))^2] =  E[(x-\\mu)^2]}\n",
    "\\end{equation*}\n",
    "\n",
    "- skew Sample skewness (third moment) of values\n",
    "    - skewness is a measure of the asymmetry of the probability distribution\n",
    "    - negative skew commonly indicates that the tail is on the left side of the distribution,\n",
    "    - positive skew indicates that the tail is on the right\n",
    "\\begin{equation*}\n",
    "skew(X) = E[(\\frac{x-\\mu}{\\sigma})^3]\n",
    "\\end{equation*}    \n",
    "\n",
    "- kurt Sample kurtosis (fourth moment) of values\n",
    "    -  person:  the fourth moment \n",
    "        - related to the tails of the distribution\n",
    "        - the sometimes-seen characterization as \"peakedness\" is mistaken\n",
    "\\begin{equation*}\n",
    "kurt(X) =  E[(\\frac{x-\\mu}{\\sigma})^4]\n",
    "\\end{equation*}\n",
    "- cumsum Cumulative sum of values\n",
    "- cummin, cummax Cumulative minimum or maximum of values, respectively\n",
    "- cumprod Cumulative product of values\n",
    "- diff Compute first arithmetic difference (useful for time series)\n",
    "    - https://machinelearningmastery.com/difference-time-series-dataset-python/\n",
    "- pct_change Compute percent changes\n",
    "- cov Covariance(协方差): how one variable varies with a second\n",
    "    - df.cov Covariance Matrix\n",
    "        - Compute pairwise covariance of columns, excluding NA/null values.\n",
    "        - return covariance matrix \n",
    "    - if cov is 0: then X and Y is indepedent\n",
    "\\begin{equation*}\n",
    "COV(x,y) = E[(x-\\mu_x)(y-\\mu_y)]\n",
    "\\end{equation*}\n",
    "\n",
    "- Correlation(相关系数): scales the covariance\n",
    "    - Correlation is a kind of normalized covariance, with a value between -1 and 1\n",
    "\\begin{equation*}\n",
    "\\rho(x,y) = COV(x,y) / \\sigma(x)\\sigma(y)\n",
    "\\end{equation*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Database Method UML\n",
    "- UML\n",
    "    - https://openclassrooms.com/en/courses/4191736-design-a-database-with-uml/4191743-learn-about-class-diagrams\n",
    "    - draw.io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Components of a Time Series\n",
    "- Trend:  The general direction in which the series is running during a long period\n",
    "- Seasonality: A seasonal pattern occurs when a time series is accted by seasonal factors such as the time of the year or the day of the week.\n",
    "- Cyclic: A cycle occurs when the data exhibit rises and falls that are not of a fixed frequency.\n",
    "    - The duration of these fluctuations is usually at least 2 years.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Autocorrelation\n",
    "- signal correlation with itself at various t\n",
    "    - [ ]the relationship with DFT\n",
    "- There are several autocorrelation coefficients,\n",
    "- pa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stationarity\n",
    "- A time series is first order stationary iff It is stationary in the mean (i.e. has constant mean).\n",
    "- A time series is second order stationary iff It is stationary in the mean & variance (constant mean, variance, covariance).\n",
    "- time series with trends/ seasonality, are not stationary\n",
    "- white noise series is stationary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matplotlib\n",
    "- s1. Get fig and axes object and initial them\n",
    "\n",
    "```\n",
    "# use Grid Axes to arrange the figure.\n",
    "widths = [4]\n",
    "heights = [1,1,1,1,1] \n",
    "\n",
    "gs_kw = dict(width_ratios=widths,height_ratios=heights)\n",
    "fig,axes = plt.subplots(nrows=5,ncols=1,figsize=[18,20],\n",
    "                        constrained_layout=True,gridspec_kw = gs_kw)\n",
    "\n",
    "fig.suptitle(main_title,y=1.0,fontsize=50)\n",
    "\n",
    "```\n",
    "\n",
    "- s2. def the plot function\n",
    "    - https://matplotlib.org/api/axes_api.html#the-axes-class \n",
    "```\n",
    "def data_plot(ax,data):\n",
    "    - ax.plot\n",
    "    \n",
    "```\n",
    "- s3. show plot:\n",
    "\n",
    "```\n",
    "plt.show\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pandas.plot()\n",
    "\n",
    "- https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.html\n",
    "- for quick plot pd.Series or pd.DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore \n",
    "\n",
    "> can use QA format\n",
    "\n",
    "- pct_change()\n",
    "- corr()\n",
    "- cov()\n",
    "- corrwith()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Groupby\n",
    "- http://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Searching\n",
    "- groupby.groups\n",
    "    - return the entry index, not the groubyed column values, id rather than values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### time-series \n",
    "#### Seasonal plots:\n",
    "- data against seasonality,\n",
    "- many lines in one graph\n",
    "- variation: polar coordinates\n",
    "- variation: \n",
    "\n",
    "#### Scatter plot\n",
    "\n",
    "- x,y axis represent the two kinds features and scatter shape represent the category.\n",
    "\n",
    "#### Scatter plot matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lag plots \n",
    "- panel 1 is the realationship between y_t and y_{t-1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ACF plot \n",
    "- correlogram\n",
    "- trend:\n",
    "    - the autocorrelations for small lags tend to be large and positive because observations nearby in time are also nearby in size.\n",
    "- seasonal: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify Data Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Data\n",
    "- http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html\n",
    "- loc: Selection By Label\n",
    "    - A single label, e.g. 5 or 'a', \n",
    "    - A list or array of labels, e.g. ['a', 'b', 'c'].\n",
    "    - A slice object with labels, e.g. 'a':'f'.\n",
    "        - both the start and the stop are included\n",
    "    - A boolean array of the same length as the axis being sliced, e.g. [True, False, True].\n",
    "    - A callable function with one argument (the calling Series, DataFrame or Panel) and that returns valid output for indexing (one of the above)\n",
    " \n",
    "- df[val] Select single column or sequence of columns from the DataFrame; special case conveniences: boolean array (filter rows), slice (slice rows), or boolean DataFrame (set values based on some criterion)\n",
    "- df.loc[val] Selects single row or subset of rows from the DataFrame by label\n",
    "- df.loc[:, val] Selects single column or subset of columns by label\n",
    "- df.loc[val1, val2] Select both rows and columns by label\n",
    "- df.iloc[where] Selects single row or subset of rows from the DataFrame by integer position\n",
    "- df.iloc[:, where] Selects single column or subset of columns by integer position\n",
    "- df.iloc[start:stop:step,:] Select all column and certain rows.\n",
    "- df.iloc[where_i, where_j] Select both rows and columns by integer position\n",
    "- df.at[label_i, label_j] Select a single scalar value by row and column label\n",
    "- df.iat[i, j] Select a single scalar value by row and column position (integers)\n",
    "- reindex method Select either rows or columns by labels\n",
    "- get_value, set_value methods Select single value by row and column label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data\n",
    "- reset_index(drop=True) :  resets the index to the default integer index.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### string and text\n",
    "\n",
    "- python built-in\n",
    "    - count Return the number of non-overlapping occurrences of substring in the string.\n",
    "    - endswith Returns True if string ends with suffix.\n",
    "    - startswith Returns True if string starts with prefix.\n",
    "    - join Use string as delimiter for concatenating a sequence of other strings.\n",
    "    - index Return position of first character in substring if found in the string; raises ValueError if not found.\n",
    "    - find Return position of first character of first occurrence of substring in the string; like index, but returns –1\n",
    "    - if not found.\n",
    "    - rfind Return position of first character of last occurrence of substring in the string; returns –1 if not found.\n",
    "    - replace Replace occurrences of string with another string.\n",
    "    - strip,\n",
    "    - rstrip,\n",
    "    - lstrip\n",
    "    - Trim whitespace, including newlines; equivalent to x.strip() (and rstrip, lstrip, respectively)\n",
    "    - for each element.\n",
    "    - split Break string into list of substrings using passed delimiter.\n",
    "    - lower Convert alphabet characters to lowercase.\n",
    "    - upper Convert alphabet characters to uppercase.\n",
    "    - casefold Convert characters to lowercase, and convert any region-specific variable character combinations to a\n",
    "     common comparable form.\n",
    "    - ljust,\n",
    "    - rjust\n",
    "    - Left justify or right justify, respectively; pad opposite side of string with spaces (or some other fill\n",
    "    - character) to return a string with a minimum width.\n",
    "\n",
    "- re module:\n",
    "    - findall Return all non-overlapping matching patterns in a string as a list\n",
    "    - finditer Like findall, but returns an iterator\n",
    "    - match Match pattern at start of string and optionally segment pattern components into groups; if the pattern matches, returns a match object, and otherwise None\n",
    "    - search Scan string for match to pattern; returning a match object if so; unlike match, the match can be anywhere in the string as opposed to only at the beginning\n",
    "    - split Break string into pieces at each occurrence of pattern\n",
    "    - sub, subn Replace all (sub) or first n occurrences (subn) of pattern in string with replacement expression; use symbols \\1, \\2, ... to refer to match group elements in the replacement string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing value\n",
    "- dropna Filter axis labels based on whether values for each label have missing data, with varying thresholds for how much missing data to tolerate.\n",
    "- fillna Fill in missing data with some value or using an interpolation method such as 'ffill' or 'bfill'.\n",
    "- isnull Return boolean values indicating which values are missing/NA.\n",
    "- notnull Negation of isnull."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randn(5,5),columns=['a', 'b', 'c', 'd', 'e'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df > 0.9] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       a      b      c      d      e\n",
       "0  False  False  False  False   True\n",
       "1  False  False  False  False  False\n",
       "2   True  False  False  False  False\n",
       "3  False  False   True  False  False\n",
       "4  False   True  False  False  False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    1\n",
       "b    1\n",
       "c    1\n",
       "d    0\n",
       "e    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers\n",
    "\n",
    "- [ ] https://scikit-learn.org/stable/auto_examples/applications/plot_outlier_detection_housing.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Data\n",
    "- pd.reindex()\n",
    "    - index New sequence to use as index. Can be Index instance or any other sequence-like Python data structure. An\n",
    "    - Index will be used exactly as is without any copying.\n",
    "    - method Interpolation (fill) method; 'ffill' fills forward, while 'bfill' fills backward.\n",
    "    - fill_value Substitute value to use when introducing missing data by reindexing.\n",
    "    - limit When forward- or backfilling, maximum size gap (in number of elements) to fill.\n",
    "    - tolerance When forward- or backfilling, maximum size gap (in absolute numeric distance) to fill for inexact matches.\n",
    "    - level Match simple Index on level of MultiIndex; otherwise select subset of.\n",
    "    - copy If True, always copy underlying data even if new index is equivalent to old index; if False, do not copy the data when the indexes are equivalent.\n",
    "\n",
    "- pd.drop()\n",
    "    - drop values from the columns by passing axis=1 or axis='columns':\n",
    "- arithmetic between objects with different indexes.\n",
    "    - By default, arithmetic between DataFrame and Series matches the index of the Series on the DataFrame’s columns, broadcasting down the rows\n",
    "    - the union of the index pairs.\n",
    "    - similar to an automatic outer join on the index labels\n",
    "    - add: NaN if not in both df.\n",
    "    - add, radd Methods for addition (+)\n",
    "    - sub, rsub Methods for subtraction (-)\n",
    "    - div, rdiv Methods for division (/)\n",
    "    - floordiv, rfloordiv Methods for floor division (//)\n",
    "    - mul, rmul Methods for multiplication (*)\n",
    "    - pow, rpow Methods for exponentiation (**)\n",
    "- NumPy ufuncs\n",
    "    - npl.abs(df)\n",
    "    - https://docs.scipy.org/doc/numpy/reference/ufuncs.html\n",
    "- df.apply(f, axis='columns')\n",
    "    - take row as series\n",
    "- sort_index()\n",
    "- sort_values()\n",
    "- rank()\n",
    "    - 'average' Default: assign the average rank to each entry in the equal group\n",
    "    - 'min' Use the minimum rank for the whole group\n",
    "    - 'max' Use the maximum rank for the whole group\n",
    "    - 'first' Assign ranks in the order the values appear in the data\n",
    "    - 'dense' Like method='min', but ranks always increase by 1 in between groups rather than the number of equal\n",
    "    - elements in a group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Utah</th>\n",
       "      <td>-1.105115</td>\n",
       "      <td>-1.716227</td>\n",
       "      <td>-0.925245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ohio</th>\n",
       "      <td>-0.914894</td>\n",
       "      <td>-0.789922</td>\n",
       "      <td>0.402857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Texas</th>\n",
       "      <td>-0.183623</td>\n",
       "      <td>0.161255</td>\n",
       "      <td>1.060435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oregon</th>\n",
       "      <td>0.430404</td>\n",
       "      <td>0.509110</td>\n",
       "      <td>1.009081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               b         d         e\n",
       "Utah   -1.105115 -1.716227 -0.925245\n",
       "Ohio   -0.914894 -0.789922  0.402857\n",
       "Texas  -0.183623  0.161255  1.060435\n",
       "Oregon  0.430404  0.509110  1.009081"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame = pd.DataFrame(np.random.randn(4, 3), columns=list('bde'),index=['Utah', 'Ohio', 'Texas', 'Oregon'])\n",
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Utah</th>\n",
       "      <td>1.105115</td>\n",
       "      <td>1.716227</td>\n",
       "      <td>0.925245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ohio</th>\n",
       "      <td>0.914894</td>\n",
       "      <td>0.789922</td>\n",
       "      <td>0.402857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Texas</th>\n",
       "      <td>0.183623</td>\n",
       "      <td>0.161255</td>\n",
       "      <td>1.060435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oregon</th>\n",
       "      <td>0.430404</td>\n",
       "      <td>0.509110</td>\n",
       "      <td>1.009081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               b         d         e\n",
       "Utah    1.105115  1.716227  0.925245\n",
       "Ohio    0.914894  0.789922  0.402857\n",
       "Texas   0.183623  0.161255  1.060435\n",
       "Oregon  0.430404  0.509110  1.009081"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Utah</th>\n",
       "      <td>-1.105115</td>\n",
       "      <td>-1.716227</td>\n",
       "      <td>-0.925245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ohio</th>\n",
       "      <td>-0.914894</td>\n",
       "      <td>-0.789922</td>\n",
       "      <td>0.402857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Texas</th>\n",
       "      <td>-0.183623</td>\n",
       "      <td>0.161255</td>\n",
       "      <td>1.060435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oregon</th>\n",
       "      <td>0.430404</td>\n",
       "      <td>0.509110</td>\n",
       "      <td>1.009081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               b         d         e\n",
       "Utah   -1.105115 -1.716227 -0.925245\n",
       "Ohio   -0.914894 -0.789922  0.402857\n",
       "Texas  -0.183623  0.161255  1.060435\n",
       "Oregon  0.430404  0.509110  1.009081"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.802165"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.246435 + 0.555730"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrate Data\n",
    "- https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pd.merge(left,right,how=,on=)\n",
    "- left DataFrame to be merged on the left side.\n",
    "- right DataFrame to be merged on the right side.\n",
    "- how One of 'inner', 'outer', 'left', or 'right'; defaults to 'inner'.\n",
    "- on Column names to join on. Must be found in both DataFrame objects. If not specified and no other join keys \n",
    "    given, will use the intersection of the column names in left and right as the join keys.\n",
    "- left_on Columns in left DataFrame to use as join keys.\n",
    "- right_on Analogous to left_on for left DataFrame.\n",
    "- left_index Use row index in left as its join key (or keys, if a MultiIndex).\n",
    "- right_index Analogous to left_index.\n",
    "- sort Sort merged data lexicographically by join keys; True by default (disable to get better performance in\n",
    "    some cases on large datasets).\n",
    "- suffixes Tuple of string values to append to column names in case of overlap; defaults to ('_x', '_y') (e.g., if  'data' in both DataFrame objects, would appear as 'data_x' and 'data_y' in result).\n",
    "- copy If False, avoid copying data into resulting data structure in some exceptional cases; by default always copies.\n",
    "- indicator Adds a special column _merge that indicates the source of each row; values will be 'left_only',\n",
    "     'right_only', or 'both' based on the origin of the joined data in each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format Data\n",
    "- https://datascience.stackexchange.com/questions/21650/feature-transformation-on-input-data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tslearn.preprocessing\n",
    "- tslearn.preprocessing.TimeSeriesScalerMinMax(min=0.0, max=1.0)\n",
    "    - Scaler for time series. Scales time series so that their span in each dimension is between min and max."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn.preprocessing\n",
    "- sklearn.preprocessing.LabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit([1, 2])\n",
    "arr = lb.transform([1, 2])\n",
    "arr.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log-scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "- Tips:\n",
    "    - when learning a new model, start from the fit function.\n",
    "\n",
    "- generative model:\n",
    "    - generative classifiers (joint distribution)\n",
    "- discriminative model (conditional distribution or no distribution)\n",
    "- several views of a model:\n",
    "    - for what kind problems:\n",
    "    - main steps\n",
    "    - effiency\n",
    "    - accuracy\n",
    "    - interpretability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Modeling Technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additive model(AM)\n",
    "- nonparametric regression\n",
    "- Suits if the size of seasonal fluctuations (or variation around the trend Tt) doesn’t vary with the time series level\n",
    "- Means the seasonality is the same (roughly constant) in same period over different years (does not depend on level)\n",
    "-  more interpretable than a general regression surface at the cost of approximation errors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiplicative Model\n",
    "- Suits if the variation in seasonal pattern or that around the trend (Tt) does vary with the time series level.\n",
    "- Sometimes seasonal effect is a proportion of underlying trend value, e.g. in previous slide, they increase with trend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive\n",
    "- all forecasts for the future are equal to the last observed value of the series\n",
    "\\begin{equation*}\n",
    "y_t = y_{t-1}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prophet\n",
    "- https://facebook.github.io/prophet/\n",
    "- https://research.fb.com/prophet-forecasting-at-scale/\n",
    "- https://pbpython.com/prophet-overview.html\n",
    "- https://colab.research.google.com/drive/1dL_XNqTg6KGjuGhSNZkajvFZQMNjcc9H?authuser=1#scrollTo=9E1nB_64XVrB\n",
    "- can not install on windows10, has a known problem.\n",
    "    - we can use colab.\n",
    "\n",
    "- Title: Forecasting at Scale\n",
    "- Review Date: 2019-3-19 12:42:302\n",
    "- Published year: 27 Sep 2017\n",
    "- Auther: Facebook\n",
    "- Unicode:\n",
    "- Useful Reference:\n",
    "- Usefulness:\n",
    "- Expression:\n",
    "    - pronounced dip around Christmas and New Year.\n",
    "    - is no exception\n",
    "    - intuitive parameters\n",
    "    - inherently different from\n",
    "- Key Words:\n",
    "    - three type scale:\n",
    "        - people\n",
    "        - variety of forecasting problems\n",
    "        - forecasting model evaluation\n",
    "- Purpose Problem: \n",
    "    - two main forecast themes:\n",
    "        - Completely automatic forecasting techniques can be brittle and they are often too inflexible to incorporate useful assumptions or heuristics.\n",
    "        - Analysts who can produce high quality forecasts are quite rare because forecasting is a specialized data science skill requiring substantial experience.\n",
    "    - a practical approach to forecasting \\at scale\" that combines configurable models with analyst-in-the-loop performance analysis\n",
    "    - high quality forecasts often far outstrips the pace at which they can be produced.\n",
    "    - Prophet’s features, \n",
    "        - like multiple seasonality\n",
    "        - changing growth rates\n",
    "        - the ability to model special days (such as Manning’s playoff and superbowl appearances)\n",
    "- Algorithm:\n",
    "    - why prophet? 6 point       \n",
    "        - hourly, daily, or weekly observations with at least a few months (preferably a year) of history\n",
    "        - more modeling flexibility,\n",
    "    - HOW prophtet work?\n",
    "        - A piecewise linear or logistic growth curve trend.\n",
    "        - A yearly seasonal component modeled using Fourier series.\n",
    "        - A weekly seasonal component using dummy variables.\n",
    "        - A user-provided list of important holidays.\n",
    "        - hundred HMC iterations\n",
    "        - We fit the Prophet model using Stan,\n",
    "            - Stan® is a state-of-the-art platform for statistical modeling and high-performance statistical computation.\n",
    "\n",
    "- Features of Business Time Series\n",
    "    - seasonality: weekly, yearly\n",
    "    - trend\n",
    "    - outliers\n",
    "    - problem of automated methods:\n",
    "        - auto.arima: large trend errors\n",
    "        - exponential smoothing : missing long-term seasonality\n",
    "        - overreact to the end of year dip.\n",
    "        - Tuning these methods requires a thorough understanding of how the underlying time series models work.\n",
    "- The prophet forecasting model\n",
    "    - handle the common features above\n",
    "    - intuitive parameters \n",
    "    - a decomposable model\n",
    "\\begin{equation*}\n",
    "y(t) = g(t) + s(t) + h(t) + \\xi_t\n",
    "\\end{equation*}\n",
    "        - g(t): trend function\n",
    "        - s(t): periodic changes，weekly and yearly seasonality\n",
    "        - h(t): effects of holidays\n",
    "        - \\xi_t: idiosyncratic changes\n",
    "        - [ ]similar to GAM\n",
    "            - decomposes easily and accommodates new components as necessary\n",
    "     - Several practical advantages:\n",
    "         - flexibility\n",
    "         - not need to be regularly spaced, not need to interpolate missing values\n",
    "\n",
    "#### The Trend Model:\n",
    "- Prophet detects changepoints by first specifying a large number of potential changepoints at which the rate is allowed to change.\n",
    "- Logistic growth model/nonlinear, saturating growth\n",
    "\n",
    "\\begin{equation*}\n",
    "g(t) = \\frac{C}{1+exp(-k(t-m))} \n",
    "\\end{equation*}\n",
    "\n",
    "    - C: carring capacity\n",
    "    - k: growth rate\n",
    "    - m : an offset parameter? How to understand this\n",
    "\n",
    "- piecewise logistic growth model\n",
    "    - for trend changes\n",
    "- piecewise constant rate growth model for forecasting.\n",
    "\\begin{equation*}\n",
    "g(t) = (k + a(t)^T\\delta)t + (m + a(t)^T\\gamma) \n",
    "\\end{equation*}  \n",
    "- automatic changepoint selection\n",
    "    - MLE\n",
    "    - [ ]a sparse prior\n",
    "\n",
    "#### Seasonality\n",
    "- standard Fourier series\n",
    "\\begin{equation*}\n",
    "s(t) = \\sum (a_n\\cos(\\frac{2\\pi nt}{P}) + b_n\\sin(\\frac{2\\pi nt}{P}))\n",
    "\\end{equation*}\n",
    "\n",
    "#### Holidays and Events\n",
    "- allow the analyst to provide a custom list of past and future events, identified by the event or holiday's unique name\n",
    "\n",
    "#### Model Fitting\n",
    "- regularization\n",
    "    - https://medium.com/datadriveninvestor/l1-l2-regularization-7f1b4fe948f2\n",
    "delta \u0018 double_exponential(0, tau);\n",
    "beta \u0018 normal(0, sigma);\n",
    "\n",
    "#### Automating Evaluation of Forecasts\n",
    "\n",
    "- Modeling Forecast Accuracy\n",
    "    - MAPE for interpretability : Mean absolute percentage error\n",
    "    \n",
    "\n",
    "***\n",
    "- Experiment:\n",
    "- Conclusion:\n",
    "- Limitation:\n",
    "- Summary:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### impletation\n",
    "\n",
    "> https://facebook.github.io/prophet/docs/quick_start.html#python-api\n",
    "- The input to Prophet is always a dataframe with two columns: ds and y\n",
    "    - ds: datestamp,  format expected by Pandas\n",
    "    - y: The y column must be numeric, and represents the measurement we wish to forecast.\n",
    "- Automatic changepoint detection in Prophet\n",
    "    - 1. specifying a large number of potential changepoints at which the rate is allowed to change\n",
    "    - 2. puts a sparse prior on the magnitudes of the rate changes : same as L1 regularization\n",
    "        - L1 regularization: https://medium.com/datadriveninvestor/l1-l2-regularization-7f1b4fe948f2\n",
    "        - Loss function is the sum of squared difference between the actual value and the predicted value\n",
    "        - by penalizing the loss function, regularization discourage the complexity of the model\n",
    "        - Regularization works on assumption that smaller weights generate simpler model and thus helps avoid overfitting.\n",
    "        - L1 regularization does feature selection. It does this by assigning insignificant input features with zero weight and useful features with a non zero weight.\n",
    "    - 3. will use as few of them as possible\n",
    "    - by increasing changepoint_prior_scale, will increase the forecast uncertainty\n",
    "\n",
    "\n",
    "\n",
    "- Holidays\n",
    "    - 1. create a dataframe for holidays\n",
    "\n",
    "- Seasonalities \n",
    "    - are estimated using a partial Fourier sum\n",
    "    - Prophet will by default fit weekly and yearly seasonalities\n",
    "    - You can add other seasonalities (monthly, quarterly, hourly) using the add_seasonality method (Python)\n",
    "    - seasonality_prior_scale which similarly adjusts the extent to which the seasonality model will fit the data.\n",
    "    - By default Prophet fits additive seasonalities, meaning the effect of the seasonality is added to the trend to get the forecast. \n",
    "    - grows with the trend. This is multiplicative seasonality.\n",
    "\n",
    "- Uncertainty Intervals\n",
    "    - There are three sources of uncertainty in the forecast: uncertainty in the trend, uncertainty in the seasonality estimates, and additional observation noise.\n",
    "    - The biggest source of uncertainty in the forecast is the potential for future trend changes.\n",
    "    - by increasing changepoint_prior_scale, will increase the forecast uncertainty\n",
    "    - To get uncertainty in seasonality, you must do full Bayesian sampling. This is done using the parameter mcmc.samples (which defaults to 0)\n",
    "\n",
    "- outliers\n",
    "    -  Prophet is able to handle the outliers in the history, but only by fitting them with trend changes.\n",
    "    - The best way to handle outliers is to remove them\n",
    "\n",
    "\n",
    "\n",
    "- Data with regular gaps\n",
    "    -  fit a daily cycle to a time series that only has data for part of the day (12a to 6a)\n",
    "    - The solution is to only make predictions for the time windows for which there are historical data.\n",
    "\n",
    "- Diagnostics : This is done by selecting cutoff points in the history, and for each of them fitting the model using data only up to that cutoff point.\n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "> key steps:\n",
    "##### step1:  import Package\n",
    "\n",
    "```\n",
    "from fbprophet import Prophet\n",
    "```\n",
    "\n",
    "\n",
    "##### step2:  a new Prophet object : Any settings to the forecasting procedure are passed into the constructor\n",
    "\n",
    "```\n",
    "playoffs = pd.DataFrame({\n",
    "  'holiday': 'playoff',\n",
    "  'ds': pd.to_datetime(['2008-01-13', '2009-01-03', '2010-01-16',\n",
    "                        '2010-01-24', '2010-02-07', '2011-01-08',\n",
    "                        '2013-01-12', '2014-01-12', '2014-01-19',\n",
    "                        '2014-02-02', '2015-01-11', '2016-01-17',\n",
    "                        '2016-01-24', '2016-02-07']),\n",
    "  'lower_window': 0,\n",
    "  'upper_window': 1,\n",
    "})\n",
    "superbowls = pd.DataFrame({\n",
    "  'holiday': 'superbowl',\n",
    "  'ds': pd.to_datetime(['2010-02-07', '2014-02-02', '2016-02-07']),\n",
    "  'lower_window': 0,\n",
    "  'upper_window': 1,\n",
    "})\n",
    "holidays = pd.concat((playoffs, superbowls))\n",
    "\n",
    "\n",
    "\n",
    "m = Prophet(changepoint_range=0.9,\n",
    "        changepoint_prior_scale=0.5,\n",
    "        changepoints=['2014-01-01'],\n",
    "        holidays = holidays,\n",
    "        yearly.seasonality = 20,\n",
    "        weekly_seasonality=False,\n",
    "        seasonality_mode='multiplicative')\n",
    "```\n",
    "- trend adjust\n",
    "    - n_changepoints\n",
    "        - number of potential changepoints\n",
    "        - By default, Prophet specifies 25 potential changepoints which are uniformly placed in the first 80% of the time series\n",
    "    - changepoint_range=0.9\n",
    "        - By default changepoints are only inferred for the first 80% \n",
    "    - changepoint_prior_scale=0.5:\n",
    "        - Adjusting trend flexibility, overfit (too much flexibility) or underfit (not enough flexibility)\n",
    "        - By default, this parameter is set to 0.05.  Increasing it will make the trend more flexible\n",
    "    - changepoints=['2014-01-01']\n",
    "        - changepoints manually\n",
    "\n",
    "- seasonality adjust:\n",
    "    \n",
    "\n",
    "- yearly.seasonality = 20\n",
    "    - Fourier order can be specified for each built-in seasonality\n",
    "- seasonality_mode:\n",
    "\n",
    "```\n",
    "\n",
    "# add Built-in Country Holidays\n",
    "m.add_country_holidays(country_name='US')\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "# add add other seasonalities (monthly, quarterly, hourly) \n",
    "# besides the default weekly and yearly seasonalities\n",
    "m.add_seasonality(\n",
    "    name='weekly', period=7, fourier_order=3, prior_scale=0.1)\n",
    "\n",
    "```\n",
    "- prior_scale=0.1: \n",
    "    - Prior scales can be set separately for individual holidays by including a column prior_scale in the holidays dataframe\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- holidays = holidays\n",
    "    - two columns (holiday and ds) and a row for each occurrence of the holiday. \n",
    "    - The holiday effect can be seen in the forecast dataframe(see s4) \n",
    "    - The holiday effects will also show up in the components plot(see s5)\n",
    "\n",
    "\n",
    "```\n",
    "# add extra regressor\n",
    "def nfl_sunday(ds):\n",
    "    date = pd.to_datetime(ds)\n",
    "    if date.weekday() == 6 and (date.month > 8 or date.month < 2):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "df['nfl_sunday'] = df['ds'].apply(nfl_sunday)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "m = Prophet()\n",
    "m.add_regressor('nfl_sunday')\n",
    "```\n",
    "- Additional regressors can be added to the linear part of the model using the add_regressor method or function\n",
    "- regressors must be added prior to model fitting.\n",
    "\n",
    "```\n",
    "m\n",
    "```\n",
    "\n",
    "##### step3: make a datafrmae include the future date you want to forecasting.\n",
    "```\n",
    "#Prophet.make_future_dataframe\n",
    "future = m.make_future_dataframe(periods=365)\n",
    "\n",
    "# only predict monthly data\n",
    "#future = m.make_future_dataframe(periods=120, freq='M')\n",
    "\n",
    "future.tail()\n",
    "```\n",
    "##### step4: Predict: The predict method will assign each row in future a predicted value which it names yhat.\n",
    "    - The predict method will assign each row in future a predicted value which it names yhat.\n",
    "```\n",
    "\n",
    "forecast = m.fit(df).predict(future)\n",
    "forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()\n",
    "\n",
    "# holiday effect\n",
    "forecast[(forecast['playoff'] + forecast['superbowl']).abs() > 0][\n",
    "        ['ds', 'playoff', 'superbowl']][-10:]\n",
    "```\n",
    "\n",
    "##### step5: Plot: plot the forecast by calling the Prophet.plot\n",
    "    - plot change points\n",
    "```\n",
    "\n",
    "# show holiday effect\n",
    "# show seasonality effect\n",
    "fig2 = m.plot_components(forecast)\n",
    "\n",
    "\n",
    "\n",
    "# show changepoints\n",
    "from fbprophet.plot import add_changepoints_to_plot\n",
    "fig = m.plot(forecast)\n",
    "a = add_changepoints_to_plot(fig.gca(), m, forecast)\n",
    "\n",
    "# plot_cross_validation_metric,\n",
    "from fbprophet.plot import plot_cross_validation_metric\n",
    "fig = plot_cross_validation_metric(df_cv, metric='mape')\n",
    "```\n",
    "\n",
    "\n",
    "##### step6: diagnostics\n",
    "\n",
    "```\n",
    "# cross_validation\n",
    "from fbprophet.diagnostics import cross_validation\n",
    "\n",
    "df_cv = cross_validation(m, initial='730 days', period='180 days', horizon = '365 days')\n",
    "df_cv.head()\n",
    "\n",
    "```\n",
    "- initial: the size of the initial training period\n",
    "    - if the cutoff is less than initial, stop calculate the cutoff.\n",
    "    - default, the initial training period is set to three times the horizon\n",
    "- horizon: forecast horizon \n",
    "    -- As a heuristic, for a forecast horizon H, we generally make a simulated forecast every H/2 periods.\n",
    "- period: spacing between cutoff dates \n",
    "    - start from every cutoff date point \n",
    "    - default: cutoffs are made every half a horizon.\n",
    "- steps:\n",
    "    - s1. get the cut off point from the end of the time-series date       \n",
    "    - s2. train the model use the data from start to the first cutoff\n",
    "    - s3. predict the cutoff + horizon data\n",
    "    - s4. move to the next cutoff, repead s2,s3 until the last cutoff\n",
    "    - s5. output a sets of prediction value, ea\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "# performance_metrics \n",
    "from fbprophet.diagnostics import performance_metrics\n",
    "df_p = performance_metrics(df_cv)\n",
    "df_p.head()\n",
    "```\n",
    "\n",
    "```\n",
    "# plot the performace metrics\n",
    "from fbprophet.plot import plot_cross_validation_metric\n",
    "fig = plot_cross_validation_metric(df_cv, metric='mape')\n",
    "```\n",
    "-  The default is 0.1, corresponding to 10% of rows from df_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# holiday example\n",
    "playoffs = pd.DataFrame({\n",
    "  'holiday': 'playoff',\n",
    "  'ds': pd.to_datetime(['2008-01-13', '2009-01-03', '2010-01-16',\n",
    "                        '2010-01-24', '2010-02-07', '2011-01-08',\n",
    "                        '2013-01-12', '2014-01-12', '2014-01-19',\n",
    "                        '2014-02-02', '2015-01-11', '2016-01-17',\n",
    "                        '2016-01-24', '2016-02-07']),\n",
    "  #'lower_window': 0,\n",
    "  #'upper_window': 1,\n",
    "})\n",
    "superbowls = pd.DataFrame({\n",
    "  'holiday': 'superbowl',\n",
    "  'ds': pd.to_datetime(['2010-02-07', '2014-02-02', '2016-02-07']),\n",
    "  'lower_window': 0,\n",
    "  'upper_window': 1,\n",
    "})\n",
    "holidays = pd.concat((playoffs, superbowls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoregression(AR)\n",
    "> https://machinelearningmastery.com/time-series-forecasting-methods-in-python-cheat-sheet/\n",
    "- the only model can use KFold cross validation\n",
    "\n",
    "\\begin{equation*}\n",
    "y_t = c + \\phi_1 y_{t-1} + \\phi_2 y_{t-2} + \\dots + \\phi_p y_{t-p} + e_t \n",
    "\\end{equation*}\n",
    "\n",
    "- et: whiti noise(WN)\n",
    "- is a multiple regression\n",
    "- y_t is the lagged value as predictions\n",
    "- if p= 1 : AR(1) model\n",
    "\n",
    "\\begin{equation*}\n",
    "y_t = c + \\phi_1 y_{t-1} + e_t \n",
    "\\end{equation*}\n",
    "\n",
    "- if \\phi_1 =0: == WN\n",
    "- if \\phi_1 = 1 and c=0,y_t = RW(Random Walk)\n",
    "\\begin{equation*}\n",
    "y_t = y_{t-1} + e_t \n",
    "\\end{equation*}\n",
    "- 0 \n",
    "    - RW model is where current value is previous plus random step up or down\n",
    "    - RW has zero mean but time-varying variance, thus is non-stationary.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100.68532718]\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.ar_model import AR\n",
    "from random import random\n",
    "\n",
    "# contrived dataset\n",
    "data = [x + random() for x in range(1,100)]\n",
    "\n",
    "# fit model\n",
    "model = AR(data)\n",
    "model_fit = model.fit()\n",
    "\n",
    "# make prediction\n",
    "yhat = model_fit.predict(len(data),len(data))\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot\n",
    "data_all = data + [yhat]\n",
    "index = range(1,len(data_all)+1)\n",
    "\n",
    "plt.plot(index,data_all)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [ ] fit and predict is very complex functions.\n",
    "- [ ] likelyhood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving Average(MA)\n",
    "\\begin{equation*}\n",
    "y_t = c + e_t + \\theta_1 e_{t-1} + \\theta_2 e_{t-2} + \\theta_q e_{t-q}\n",
    "\\end{equation*}\n",
    "- et: white noise\n",
    "- is a multiple regression with past errors as predictors\n",
    "- uses past forecast errors in a regression-like model\n",
    "- Don’t confuse this with moving average smoothing\n",
    "- The method is suitable for univariate time series without trend and seasonal components.\n",
    "- the average method assumes that all observations are of equal importance, and gives them equal weights when generating forecasts.\n",
    "    - [ ] How to decompose the trend and seasonal components?\n",
    "\\begin{equation*}\n",
    "\\hat{y_t} = \\frac{1}{m} \\sum y_{t+j}\n",
    "\\\\\n",
    "m = 2k+1,j= [-k,k]\n",
    "\\end{equation*}\n",
    "- It is possible to write any stationary AR( ) model as an MA( ) model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[74.71912804]\n"
     ]
    }
   ],
   "source": [
    "# MA example\n",
    "from statsmodels.tsa.arima_model import ARMA\n",
    "from random import random\n",
    "\n",
    "# contrived dataset\n",
    "data = [x+ random() for x in range(1,100)]\n",
    "\n",
    "# fit model\n",
    "model = ARMA(data,order=(0,1))\n",
    "model_fit = model.fit(disp=False)\n",
    "\n",
    "# make prediction\n",
    "yhat = model_fit.predict(len(data),len(data))\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x25e89332fd0>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot\n",
    "data_all = data + [yhat]\n",
    "index = range(1,len(data_all)+1)\n",
    "\n",
    "plt.plot(index,data_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  ARMA\n",
    "- with both MA&AR terms, no differencing\n",
    "\\begin{equation*}\n",
    "y_t = c + \\phi_1 y_{t-1} + \\phi_2 y_{t-2} + \\dots + \\phi_p y_{t-p} + e_t + \\theta_1 e_{t-1} + \\theta_2 e_{t-2} + \\theta_q e_{t-q}\n",
    "\\end{equation*}\n",
    "- Conditions on coefficients ensure stationarity.\n",
    "- Conditions on coefficients ensure invertibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.57169792]\n"
     ]
    }
   ],
   "source": [
    "# ARMA example\n",
    "from statsmodels.tsa.arima_model import ARMA\n",
    "from random import random\n",
    "# contrived dataset\n",
    "data = [random() for x in range(1, 100)]\n",
    "# fit model\n",
    "model = ARMA(data, order=(2, 1))\n",
    "model_fit = model.fit(disp=False)\n",
    "# make prediction\n",
    "yhat = model_fit.predict(len(data), len(data))\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  ARIMA (Autoregressive Integrated Moving Average)\n",
    "\n",
    "- auto.arima in R: automatically selects the best one\n",
    "\n",
    "\\begin{equation*}\n",
    "y'_t = c + \\phi_1 y'_{t-1} + \\phi_2 y'_{t-2} + \\dots + \\phi_p y'_{t-p} + e_t + \\theta_1 e_{t-1} + \\theta_2 e_{t-2} + \\theta_q e_{t-q}\n",
    "\\end{equation*}\n",
    "\n",
    "- y'_t : differenced series\n",
    "    - for d = 1, y'_t = y_t - y_{t-1}\n",
    "- AR: p = order of the autoregressive part\n",
    "- I: d = degree of first differencing involved\n",
    "    - for \n",
    "- MA: q = order of the moving average part.\n",
    "- The method is suitable for univariate time series with trend and without seasonal components.\n",
    "- Models written in terms of lagged variables (which ARIMA is) work only on equally-spaced time periods.\n",
    "- generative model   https://en.wikipedia.org/wiki/Generative_model\n",
    "- Backshift notation\n",
    "     - B operating on y_t, \n",
    "\\begin{equation*}\n",
    "By_t = y_{t-1}\n",
    "\\\\\n",
    "y'_t = y_t - y_{t-1} = y_t -  By_t = (1-B)y_t\n",
    "\\\\\n",
    "y\"_t = y_t - 2y_{t-1}+y_{t-2} = (1-B)^2y_t\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100.52892407]\n"
     ]
    }
   ],
   "source": [
    "# ARIMA example\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from random import random\n",
    "# contrived dataset\n",
    "data = [x + random() for x in range(1, 100)]\n",
    "# fit model\n",
    "model = ARIMA(data, order=(1, 1, 1))\n",
    "model_fit = model.fit(disp=False)\n",
    "# make prediction\n",
    "yhat = model_fit.predict(len(data), len(data), typ='levels')\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First order stationarity:\n",
    "    - A time series is first order stationary iff It is stationary in the mean (i.e. has constant mean).\n",
    "- ACF: Auto-Correlation Functions\n",
    "- PACF: Power  Auto-Correlation Functions\n",
    "- use ACF and PACF plot to determine appropriate values for p and q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SARIMA  Seasonal Autoregressive Integrated Moving-Average\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discrete Model : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Difference Equation\n",
    "- Ex1. Rabbit Reproduction\n",
    "- s1. write the difference equation set\n",
    "\\begin{equation*}\n",
    "M_{n+2} = M_{n+1} + M_n\n",
    "\\\\\n",
    "M_{n+1} = M_{n+1} + 0\n",
    "\\end{equation*}\n",
    "- s1. according the equation set, write the system Matric A:\n",
    "\\begin{equation*}\n",
    "A = \\binom{1,1}{1,0}\n",
    "\\end{equation*}\n",
    "- s3. write the characteristic equation:\n",
    "\\begin{equation*}\n",
    "\\binom{1-\\lambda,1}{1,-\\lambda} = 0\n",
    "\\end{equation*}\n",
    "- s4. calculate the eigenvalue \\lambda\n",
    "\\begin{equation*}\n",
    "\\lambda_{1,2} = \\frac{1\\pm \\sqrt{5}}{2}\n",
    "\\end{equation*}\n",
    "- s5. write out the eigendecomposition of A\n",
    "\\begin{equation*}\n",
    "A = \\frac{1}{\\lambda_1 - \\lambda_2} \\binom{\\lambda_1,\\lambda_2}{1,1} \\binom{\\lambda_1,0}{0,\\lambda_2} \\binom{1,-\\lambda_2}{-1,\\lambda_1} = \\binom{\\lambda_1 + \\lambda_2, -\\lambda_1 \\lambda_2}{1,0}\n",
    "\\end{equation*}\n",
    "- s6. write out the n generation A^n\n",
    "\\begin{equation*}\n",
    "A = SAS^{-1}\n",
    "\\\\\n",
    "A^n = SA^nS^{-1}\n",
    "\\end{equation*}\n",
    "- put A^n in the model equation\n",
    "\\begin{equation*}\n",
    "\\mu_n = A^n \\mu_0 = SA^nS^{-1} \\mu_0\n",
    "\\\\\n",
    "\\mu_n = \\binom{u_1}{u_2} = c_1 \\lambda_1^n v_1 + c_2 \\lambda_2^2 v_2\n",
    "\\end{equation*}\n",
    "\n",
    "- Ex2:The Leslie Matrix\n",
    "    - normally test its stability \\lambda > 1 : increase\n",
    "\\begin{equation*}\n",
    "P(n) \\approx c_1\\lambda_1^n v_1\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Based Model \n",
    "\n",
    "#### Linear Regression\n",
    "- s1. a linear model\n",
    "\\begin{equation*}\n",
    "M_w(d) = w[0] + w[1] * d[1]\n",
    "\\end{equation*}\n",
    "\n",
    "- s2. an error function\n",
    "    - this function include the weight of the model, so optimal this function can optimal the model\n",
    "\\begin{equation*}\n",
    "L_2 (M_w, D) = 1/2 \\sum (t_i - M_w(d_i))^2\n",
    "\\\\\n",
    "M_w(d_i) = w \\cdot d\n",
    "\\end{equation*}\n",
    "\n",
    "- ith instance/entries, and jth features.\n",
    "\n",
    "- s3. optimise the error function\n",
    "    - error surface is convex and have a gloabl minimum\n",
    "\n",
    "#### Gradient Decent    \n",
    "- S1. selecting a random point within the weight space\n",
    "    - based on empirical evidence, choosing random initial weights uniformly from the range [−0.2, 0.2] tends to work well.\n",
    "- S2. calculate a prediction based on the initial weitht\n",
    "    - need a parameterized model such as LR\n",
    "- S3. calculate the error between target and prediction\n",
    "    - need an error function such as LSE\n",
    "- S4. calculate eerorDelta\n",
    "\\begin{equation*}\n",
    "errorDelta(D,w[j]) = - \\frac{\\partial L_2(M_w,D)}{\\partial w[j]} = \\sum ((t_i - M_w(d_i)) * d_i[j])\n",
    "\\end{equation*}\n",
    "- S5. update the w_j\n",
    "    - need decide learning rate\n",
    "    - Setting the Learning Rate Using Weight Decay\n",
    "\\begin{equation*}\n",
    "w[j] = w[j] + \\alpha * errorDelta(D,w[j])\n",
    "\\end{equation*} \n",
    "- S6. calculate new prediction based on the new weitht\n",
    "- S7. repeate S3-S6. untile get the convergence.\n",
    "- S8. at this stage, the new weight represent the model.\n",
    "- S9. Interprete the weight\n",
    "    - A better way to determine the importance of each descriptive feature in the model is to perform a statistical significance test\n",
    "\n",
    "- Categorical Features\n",
    "    - converts a single categorical descriptive feature into a number of continuous descriptive feature values that can encode the levels of the categorical feature.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression\n",
    "- Handling Categorical Target Features\n",
    "- since the hard decision boundary is not continuous,so it is not differentiable : logistic function\n",
    "- datasets in which the instances with target features set to different levels overlap with each other in the feature space.\n",
    "\\begin{equation*}\n",
    "logistic(x) = \\frac{1}{1+e^{-x}} = \\frac{e^x}{1+e^x}\n",
    "\\\\\n",
    "\\frac{dlogistic(x)}{dx} = logsitic(x) (1 - logistic(x))\n",
    "\\end{equation*}\n",
    "\n",
    "- logistc Regression Model\n",
    "\\begin{equation*}\n",
    "M_w(d) = logistic(w d) = \\frac{1}{1+e^{-wd}}\n",
    "\\end{equation*}\n",
    "\n",
    "- similar as s5 in linar regression\n",
    "\\begin{equation*}\n",
    "w[j] = w[j] + \\alpha * errorDelta(D,w[j]) = w[j] + \\alpha * \\sum ((t_i - M_w(d_i))*  M_w(d_i) * (1 - M_w(d_i)) * d_i[j])\n",
    "\\end{equation*}\n",
    "\n",
    "#### Normalizaiton\n",
    "- advantage\n",
    "    - The main advantages of normalizing descriptive feature values are that all weights become directly comparable with each other\n",
    "        - and the behavior of the gradient descent algorithm used to train the model becomes much less sensitive to the learning rate and the initial weights\n",
    "    - for logistic regression models we recommend that descriptive feature values always be normalized.\n",
    "- disadvantage\n",
    "    - more difficult for interprete the weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non-linear Relationships\n",
    "- introduce basis functions that transform the raw inputs to the model into non-linear representations\n",
    "- lineaar regression for non-linear basis\n",
    "\\begin{equation*}\n",
    "M_w(d) = \\sum w[k] * \\phi_k(d)\n",
    "\\end{equation*}\n",
    "- a quadratic function basis example:\n",
    "\\begin{equation*}\n",
    "\\phi_1(d) = 1\n",
    "\\phi_2(d) = d\n",
    "\\phi_3(d) = d^2\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multinomial Logistic Regression\n",
    "- handles categorical target features with more than two levels\n",
    "- A good way to build multinomial logistic regression models is use a set of one-versus-all models.\n",
    "- main steps:\n",
    "- S1: For r target feature levels, we build r separate logistic regression models\n",
    "    - trained in parallel\n",
    "\\begin{equation*}\n",
    "M_{w_1}(d) = logistic(W_1 d)\n",
    "M_{w_2}(d) = logistic(w_2 d)\n",
    "\\end{equation*}\n",
    "- S2: Normalize for combine the different models\n",
    "    - revised,normalized prediction\n",
    "\\begin{equation*}\n",
    "M^{,}_{w_k} = \\frac{M_{w_k (d)}}{\\sum{M_{w_k (d)}}\n",
    "\\end{equation*}\n",
    "- S3. use the revise,normalized prediction in the loss function\n",
    "    - the highest prediction, the class belong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM\n",
    "- Margin: This distance from the decision boundary to the nearest training instance is known as the margin\n",
    "- Training a support vector machine involves searching for the decision boundary, or separating hyperplane,20 that leads to the maximum margin as this will best separate the levels of the target feature.\n",
    "- Support Vectors: The instances in a training dataset that fall along the margin extents, and so define the margins, are known as the support vectors.\n",
    "- Support Vector Machine:\n",
    "    - When theoutput of this equation is greater than 1, we predict the positive target level for the query, and when the output is less than −1, we predict the negative target level.\n",
    "\\begin{equation*}\n",
    "M_{\\alpha,w_0}(q) = \\sum (t_i \\times \\alpha[i] \\times (d_i \\cdot q) + w_0)\n",
    "\\end{equation*}\n",
    "- constrained quadratic optimization problem\n",
    "- constrained part\n",
    "\\begin{equation*}\n",
    "t_i \\times (w_0 + w \\cdot d) \\ge 1\n",
    "\\end{equation*}\n",
    "- optimization criterion\n",
    "\\begin{equation*}\n",
    "dist(d) = \\frac{w_0 + w \\cdot d}{\\|w \\|}\n",
    "\\end{equation*}\n",
    "- The goal when training a support vector machine is to maximize subject\n",
    "\\begin{equation*}\n",
    "\\frac{2}{\\|w \\|}\n",
    "\\end{equation*}\n",
    "\n",
    "##### Non linear\n",
    "- basis functions can be used with support vector machines to handle training data that is not linearly separable.\n",
    "\\begin{equation*}\n",
    "t_i \\times (w_0 + w \\cdot \\phi(d)) \\ge 1\n",
    "\\end{equation*}\n",
    "- the new prediction model\n",
    "M_{\\alpha,w_0}(q) = \\sum (t_i \\times \\alpha[i] \\times (\\phi(d_i) \\cdot \\phi(q)) + w_0)\n",
    "- kernel trick\n",
    "    - A dot product of two high-dimensional vectors is a computationally expensive operation\n",
    "    - three kernel:\n",
    "        - linear/polynomial/Gaussian radial basis kernel\n",
    "    - It is best to start with a simple linear or low-degree polynomial kernel function and move to more complex kernel functions only if good performance cannot be achieved with this.\n",
    "\\begin{equation*}\n",
    "M_{\\alpha,kernel,w_0}(q) = \\sum (t_i \\times \\alpha[i] \\times kernel(d_i \\cdot q) + w_0)\n",
    "\\end{equation*}\n",
    "- Non-seperate problem: An extension of the standard support vector machine approach that allows a soft margin\n",
    "- not verey interpretable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Shapelets\n",
    "\n",
    "- Notations in the paper:\n",
    "    - I: number of training instances\n",
    "    - Q: the length of the single time-series.\n",
    "    - K: Number of Shapelets\n",
    "    - L: length of a shapelets\n",
    "    - \\lambda_W : Regularization\n",
    "    - \\eta: Learning Rate\n",
    "    - maxIter: Number of iteration\n",
    "\n",
    "- key Steps:\n",
    "- S1. A model function\n",
    "- S2. Loss function\n",
    "- S3. Objective function\n",
    "- S4. G\n",
    "    - updates the values of the shapelets\n",
    "and weights in the negative direction of the derivative with respect\n",
    "to the classification objective of each training instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tslearn Implementation\n",
    "- https://tslearn.readthedocs.io/en/latest/\n",
    "- http://fs.ismll.de/publicspace/LearningShapelets/\n",
    "\n",
    "-  time series is nothing more than a two-dimensional numpy array with its first dimension corresponding to the time axis and the second one being the feature dimensionality (1 by default).\n",
    "- Then, if we want to manipulate sets of time series, we can cast them to three-dimensional arrays, using to_time_series_dataset. If time series from the set are not equal-sized, NaN values are appended to the shorter ones and the shape of the resulting array is (n_ts, max_sz, d) where max_sz is the maximum of sizes for time series in the set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### S1. Import and split dataset\n",
    "```\n",
    "from tslearn.datasets import UCR_UEA_datasets\n",
    "\n",
    "datasets = UCR_UEA_datasets()\n",
    "dataset_list = datasets.list_datasets()\n",
    "\n",
    "ecg200 = datasets.load_dataset('ECG200')\n",
    "X_train, y_train, X_test, y_test = ecg200\n",
    "```\n",
    "\n",
    "##### S2. Transform Dataset\n",
    "```\n",
    "from tslearn.preprocessing import TimeSeriesScalerMinMax\n",
    "\n",
    "X_train = TimeSeriesScalerMinMax().fit_transform(X_train)\n",
    "X_test = TimeSeriesScalerMinMax().fit_transform(X_test)\n",
    "```\n",
    "\n",
    "##### S5. Initial the shapelet size\n",
    "- a parameter for shapelet model(next step)\n",
    "\n",
    "- Start with rough initial guesses for the shapelets,\n",
    "\n",
    "```\n",
    "from tslearn.shapelets import grabocka_params_to_shapelet_size_dict\n",
    "\n",
    "shapelet_sizes = grabocka_params_to_shapelet_size_dict(n_ts=X_train.shape[0],\n",
    "                                                       ts_sz=X_train.shape[1],\n",
    "                                                       n_classes=len(set(y_train)),\n",
    "                                                       l=0.1,\n",
    "                                                       r=2\n",
    "                                                       \n",
    "\n",
    "base_size = int(l * ts_sz)\n",
    "d = {}\n",
    "for sz_idx in range(r):\n",
    "    shp_sz = base_size * (sz_idx + 1)\n",
    "    //ts_sz - shp_sz + 1 is the sliding window segments number\n",
    "    // why need numpy.log10 ?\n",
    "    n_shapelets = int(numpy.log10(n_ts * (ts_sz - shp_sz + 1) * (n_classes - 1)))\n",
    "    d[shp_sz] = n_shapelets\n",
    "return d\n",
    "                                                     \n",
    "```\n",
    "- n_ts (int) – Number of time series in the dataset : the I in paper\n",
    "- ts_sz (int) – Length of time series in the dataset: the Q in paper\n",
    "- n_classes (int) – Number of classes in the dataset\n",
    "- l (float) – Fraction of the length of time series to be used for base shapelet length\n",
    "- r (int) – Number of different shapelet lengths to use\n",
    "- return: dict, Dictionnary giving, for each shapelet length, the number of such shapelets to be generated\n",
    "- d[shp_sz] = n_shapelets\n",
    "- shp_sz: lenth of shapelets \n",
    "- n_shapelets: repectively number of shapelets. K in paper\n",
    "\n",
    "\n",
    "##### S6: initial shapelet model\n",
    "- Iteratively learn/optimize the shapelets by minimizing a classification loss function\n",
    "- a novel classification model that is differentiable with respect to shapelets. Therefore, shapelets can be updated in a stochastic gradient descent optimization fashion, by taking steps towards the minimum of the classification loss function (i.e. towards maximal prediction accuracy).\n",
    "\n",
    "- for each shapests set combination, \n",
    "\n",
    "```\n",
    "shp_clf = ShapeletModel(n_shapelets_per_size=shapelet_sizes,\n",
    "                        optimizer=Adagrad(lr=.1),\n",
    "                        weight_regularizer=.01,\n",
    "                        max_iter=20000,\n",
    "                        verbose_level=0)\n",
    "```\n",
    "- n_shapelets_per_size: dict\n",
    "    - Dictionary giving, for each shapelet size (key),\n",
    "    - the number of such shapelets to be trained (value)\n",
    "- max_iter: int (default: 1000)\n",
    "    - Number of training epochs.\n",
    "- batch_size: int (default:256)\n",
    "    - Batch size to be used.\n",
    "- verbose_level: {0, 1, 2} (default: 2)\n",
    "    - `keras` verbose level.\n",
    "- optimizer: str or keras.optimizers.Optimizer (default: \"sgd\")\n",
    "    - `keras` optimizer to use for training.\n",
    "- weight_regularizer: float or None (default: None)\n",
    "    - Strength of the L2 regularizer to use for training the classification (softmax) layer. If None, no regularization is performed.\n",
    "- random_state : int or None, optional (default: None) The seed of the pseudo random number generator to use when shuffling the data.  If int, random_state is the seed used by the random number generator; If None, the random number generator is the RandomState instance used by `np.random`.\n",
    " \n",
    "##### S7.  fit the model\n",
    "\n",
    "\n",
    "```\n",
    "shp_clf.fit(X_train, y_train)\n",
    "```\n",
    "- X : array-like of shape=(n_ts, sz, d)\n",
    "    - Time series dataset.\n",
    "- y : array-like of shape=(n_ts, )\n",
    "    - Time series labels.\n",
    "\n",
    "##### S8. predict\n",
    "```\n",
    "predicted_locations = shp_clf.locate(X_test)\n",
    "predicted_labels = shp_clf.predict(X_test)\n",
    "```\n",
    "\n",
    "##### S9. visualize results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mining Association Rules\n",
    "- assume all data are categorical\n",
    "- not good for numeric data\n",
    "- initially used for Market Basket Analysis \n",
    "\n",
    "#### Notations\n",
    "- I = {i_1,I_2,...,I_m} a set of items.\n",
    "- t: transaction: a set of items, and t ∈I.\n",
    "    - may have TID(transaction ID)\n",
    "- T: Transaction database: a set of transactions. \n",
    "    - T = {t_1,t_2,..,t_n}\n",
    "#### Association Rules:\n",
    "- A transaction t contains X(itemset/a pattern/ a set of items ) in I.\n",
    "- An association rule is an implication of the form:\n",
    "    - X-> Y, where X, Y ∈ I, and X ∩ Y = ∅\n",
    "- A k-itemset is an itemset with k items.\n",
    "\n",
    "##### Measure the strenght of Rules.\n",
    "- Support : transactions contain X ∪ Y\n",
    "    - sup = Pr(EX ∩ EY)\n",
    "- Confidence: transactions that contain X also contian Y.\n",
    "    - conf(X->Y) = Pr(EY|EX) = Pr(EX ∩ EY)/Pr(EX)\n",
    "- Lift: if the observed support were statistically independent\n",
    "    - sup/ Pr(EX) * Pr(EY)\n",
    "- Conviction: ration to that if the events were statidstically indepnedent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA (Principal Component Analysis)\n",
    "\n",
    "- interpretable: each PC \n",
    "\n",
    "> https://skymind.ai/wiki/eigenvector\n",
    "\n",
    "- eigenvector : the direction of the wind\n",
    "    - the one that changes length but not direction by a matrix\n",
    "    - a n* n matrix have n eigenvectors.\n",
    "    - a 2x2 matrix have two eigenvectors[[0,1],[1,0]], it is Cartesian coordinate system(rectangular coordinate system)\n",
    "        - eigenvectors is Orthogonal \n",
    "\n",
    "- PCA concept\n",
    "    - 12 = 2 × 2 × 3: the decomposition give more information to the object(12), \n",
    "    - preprocess data for their neural networks.\n",
    "    - PCA attempts to draw straight, explanatory lines through data, like linear regression.\n",
    "    - Each straight line represents a “principal component,”,a relationship between an independent and dependent variable.\n",
    "- PCA on Covariance Matrix\n",
    "    - n * m matrics M_{n * m}: (n time-series, m features)\n",
    "    - M * M^T.shape == n* n : it is  a square and symmetric matrix. \n",
    "    - symmetric matrix, the eigenvalues are always real and the corresponding eigenvectors are always orthogonal.\n",
    "    - [ ] matrix discribe the covariance matrix\n",
    "    - Finding the eigenvectors and eigenvalues of the covariance matrix is the equivalent of fitting those straight, principal-component lines to the variance of the data. \n",
    "    - ranking your eigenvectors in order of their eigenvalues, highest to lowest, you get the principal components in order of significance.\n",
    "\t\n",
    "    \n",
    " - relation to Entropy & Information Gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Test Design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "- RMSLE root mean squared logarithmic error.\n",
    "    - often used in kaggle regression problem\n",
    "```\n",
    "def rmsle(real, predicted):\n",
    "    sum=0.0\n",
    "    for x in range(len(predicted)):\n",
    "        if predicted[x]<0 or real[x]<0: #check for negative values\n",
    "            continue\n",
    "        p = np.log(predicted[x]+1)\n",
    "        r = np.log(real[x]+1)\n",
    "        sum = sum + (p - r)**2\n",
    "    return (sum/len(predicted))**0.5\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For time-series\n",
    "- The accuracy of forecasts can only be determined by considering how well a model performs on new data that were not used when 􀁿tting the model.\n",
    "\n",
    "### Residuals: what is left over after fitting a model\n",
    "    - A good forecasting method:\n",
    "        - The residuals are uncorrelated.\n",
    "            - if not: then there is information left in the residuals\n",
    "        - The residuals have zero mean.\n",
    "            - If the residuals have a mean other than zero, then the forecasts are biased.\n",
    "        - The residuals have constant variance\n",
    "        - The residuals are normally distributed\n",
    "\\begin{equation*}\n",
    "e_t = y_t - \\hat{y_t}\n",
    "\\end{equation*}\n",
    "\n",
    "### Traing and Test set\n",
    "- The test set should ideally be at least as large as the maximum forecast horizon required.\n",
    "\n",
    "### Forecast errors\n",
    "- not the mistake it means the unpredictable part of an observation\n",
    "-  VS Residuals:\n",
    "    - residuals are calculated on the training set while forecast errors are calculated on the test set\n",
    "    - Second, residuals are based on one-step forecasts while forecast errors can involve multi-step forecasts.\n",
    "### Scale-dependent errors\n",
    "#### MAE (Mean absolute error)\n",
    "\\begin{equation*}\n",
    "MAE = mean(|e_t|)\n",
    "\\end{equation*}\n",
    "\n",
    "#### RMSE (Root mean squared error)\n",
    "\\begin{equation*}\n",
    "RMSE = \\sqrt{mean(e_t^2)}\n",
    "\\end{equation*}\n",
    "- A forecast method that minimises the MAE will lead to forecasts of the median, while minimising the RMSE will lead to forecasts of the\n",
    "mean.\n",
    "\n",
    "### Percentage errors\n",
    "- unit-free\n",
    "#### MAPE (Mean absolute percentage error)\n",
    "- disadvantage:\n",
    "    - if y is small or to zero. the p_t is very large\n",
    "    - put a heavier penalty on negative errors than on positive errors\n",
    "\\begin{equation*}\n",
    "MAPE = mean(|p_t|)\n",
    "\\\\\n",
    "p_t = 100e_t/y_t\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "### Scaled errors\n",
    "#### MASE(Mean absolute scaled error)\n",
    "\n",
    "### Cross validation\n",
    "- test is a single observation\n",
    "- forecast accuracy is computed by averaging over the test sets\n",
    "- A good way to choose the best forecasting model is to 􀁿nd the model with the smallest RMSE computed using time series cross-validation.\n",
    "- https://robjhyndman.com/hyndsight/tscv/\n",
    "\n",
    "- prophet\n",
    "- rolling origin\" forecast evaluation procedures / evaluation on a rolling forecasting origin”\n",
    "\n",
    "\n",
    "### Prediction intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Test\n",
    "\n",
    "### T-test\n",
    "- this is a two tailed t-test with degrees of freedom set to the number of instances in the training set minus 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Linear Regression\n",
    "- First, the signs of the weights indicate whether different descriptive features have a positive or a negative impact on the prediction.\n",
    "- the magnitudes of the weights show how much the value of the target feature changes for a unit change in the value of a particular descriptive feature.\n",
    "- A better way to determine the importance of each descriptive feature in the model is to perform a statistical significance test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Math Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Higher Mathematics\n",
    "- derivate is from limit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear algebra\n",
    "- characteristic equation:\n",
    "\\begin{equation*}\n",
    "det(A - \\lambda I) = 0\n",
    "\\\\\n",
    "\\lambda^2 - p\\lambda + q = 0\n",
    "\\\\\n",
    "p = a_11 + a_22; q = a_11 a_22 - a_12 a_21\n",
    "\\\\\n",
    "\\lambda_{1,2} = \\frac{p}{2} \\pm \\frac{\\sqrt{p^2 - 4q}}{2}\n",
    "\\\\\n",
    "\\lambda_1 + \\lambda_2 = - \\frac{b}{a} = -\\frac{-p}{1} = p\n",
    "\\\\\n",
    "\\lambda_1 * \\lambda_2 = \\frac{c}{a} = \\frac{q}{1} = q\n",
    "\\end{equation*}\n",
    "\n",
    "- for second order matrix, a eigendecomposition:\n",
    "\\begin{equation*}\n",
    "A = \\frac{1}{\\lambda_1 - \\lambda_2} \\binom{\\lambda_1,\\lambda_2}{1,1} \\binom{\\lambda_1,0}{0,\\lambda_2} \\binom{1,-\\lambda_2}{-1,\\lambda_1} = \\binom{\\lambda_1 + \\lambda_2, -\\lambda_1 \\lambda_2}{1,0}\n",
    "\\\\\n",
    "S * S^{-1} = \\dbinom{\\lambda_1 - \\lambda_2,0}{0,\\lambda_1 - \\lambda_2}\n",
    "\\\\\n",
    "v1 = C \\dbinom{\\lambda_1}{1}, v2 = C \\dbinom{\\lambda_2}{1}\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "- a second order ODE system has a solution:\n",
    "\\begin{equation*}\n",
    "\\mathbf{x(t)} = \\dbinom{x(t)}{y(t)} = c_1 v_1 e^{\\lambda_1t} + c_2 v_2 e^{\\lambda_2t}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "578px",
    "width": "547px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "402px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
